# @format
# docker-compose.yml
# version: '3.8'
services:
    sbx1:
        container_name: 1_gpt-4.1-nano-2025-04-14
        build:
            context: .
            args:
                - HF_API_KEY=${HF_API_KEY}
        runtime: nvidia
        env_file:
            - ../.env
        environment:
            MODEL_ID: gpt-4.1-nano-2025-04-14
            SBX_ID: 1
            HF_HOME: ${HF_CACHE_PATH}/huggingface
        volumes:
            - '/mnt/c/Work/CoT:/app'
            - '/mnt/e/CoT_Result/logs:/logs'
            - '/mnt/e/CoT_Result/backups:/backups'
        working_dir: /app
        command: conda run -n pilot python -u main.py
    sbx2:
        container_name: 2_claude-sonnet-4-20250514
        build:
            context: .
            args:
                - HF_API_KEY=${HF_API_KEY}
        runtime: nvidia
        env_file:
            - ../.env
        environment:
            MODEL_ID: claude-sonnet-4-20250514
            SBX_ID: 2
            HF_HOME: ${HF_CACHE_PATH}/huggingface
        volumes:
            - '/mnt/c/Work/CoT:/app'
            - '/mnt/e/CoT_Result/logs:/logs'
            - '/mnt/e/CoT_Result/backups:/backups'
        working_dir: /app
        command: conda run -n pilot python -u main.py
    sbx3:
        container_name: 3_grok-4-0709
        build:
            context: .
            args:
                - HF_API_KEY=${HF_API_KEY}
        runtime: nvidia
        env_file:
            - ../.env
        environment:
            MODEL_ID: grok-4-0709
            SBX_ID: 3
            HF_HOME: ${HF_CACHE_PATH}/huggingface
        volumes:
            - '/mnt/c/Work/CoT:/app'
            - '/mnt/e/CoT_Result/logs:/logs'
            - '/mnt/e/CoT_Result/backups:/backups'
        working_dir: /app
        command: conda run -n pilot python -u main.py
    # Test Only : Local model
    sbx4:
        container_name: 4_meta-llama_Llama-3.1-8B-Instruct
        build:
            context: .
            args:
                - HF_API_KEY=${HF_API_KEY}
        runtime: nvidia
        env_file:
            - ../.env
        environment:
            MODEL_ID: meta-llama/Llama-3.1-8B-Instruct
            SBX_ID: 4
            HF_HOME: ${HF_CACHE_PATH}/huggingface
        volumes:
            - '/mnt/c/Work/CoT:/app'
            - '/mnt/e/CoT_Result/logs:/logs'
            - '/mnt/e/CoT_Result/backups:/backups'
        working_dir: /app
        command: conda run -n pilot python -u main.py
