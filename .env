# .env Template

# API_KEY
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
XAI_API_KEY=
GOOGLE_GENAI_API_KEY=
HF_API_KEY=

# Work_Dir_Path
LOG_DIR=
BACKUP_DIR=
DATASET_PATH=
RESULTS_DIR=
HF_CACHE_PATH=

# LLM generation parameters
TEMPERATURE=0.3
MAX_NEW_TOKENS=1024
TOP_P=0.9
TOP_K=50
REPETITION_PENALTY=1.2

# Reward function hyperparameters
# θc: complexity threshold, θa: answer correctness threshold
THETA_C=0.02  # θc: complexity alignment tolerance
THETA_A=0.02  # θa: correctness alignment tolerance
# Reward weights (How vs Which)
REWARD_COMPLEXITY=0.36  # weight for process complexity (How)
REWARD_CORRECTNESS=0.39  # weight for answer correctness (Which)
REWARD_COHERENCE=0.25
SPACY_SIMILARITY_THRESHOLD=0.77
REWARD_WINDOW_SIZE=2

# The count of sentences for one item cannot be more than 3x the count for another.
WHW_RULES_MIN_TOTAL_SENTENCE=6
WHW_RULES_MAX_BALANCE_RATIO=2.99

# Experiment Settings
NUM_QUESTIONS=10
START_TRIAL=4
TOTAL_RUNS=16
DEFAULT_SEED=42